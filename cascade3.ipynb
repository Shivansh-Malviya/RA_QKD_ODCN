{"metadata":{"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":9617617,"sourceType":"datasetVersion","datasetId":5869542}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install qiskit qiskit-aer shortuuid","metadata":{"vscode":{"languageId":"raw"},"execution":{"iopub.status.busy":"2024-10-13T21:24:58.836517Z","iopub.execute_input":"2024-10-13T21:24:58.837822Z","iopub.status.idle":"2024-10-13T21:24:58.840710Z","shell.execute_reply.started":"2024-10-13T21:24:58.837776Z","shell.execute_reply":"2024-10-13T21:24:58.840053Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#!/usr/bin/env python\n# coding: utf-8\n\nimport numpy as np\nfrom qiskit import *\nimport time\nimport multiprocessing as mp\nimport tensorflow as tf\nfrom multiprocessing import cpu_count","metadata":{"execution":{"iopub.status.busy":"2024-10-13T21:24:58.841984Z","iopub.execute_input":"2024-10-13T21:24:58.842437Z","iopub.status.idle":"2024-10-13T21:24:58.851465Z","shell.execute_reply.started":"2024-10-13T21:24:58.842390Z","shell.execute_reply":"2024-10-13T21:24:58.850851Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Importing Qiskit\nfrom qiskit.qasm2 import dumps\nfrom qiskit_aer import Aer\nimport matplotlib.pyplot as plt\n\nimport hashlib\nimport base64\nfrom numpy import log as ln\nimport shortuuid\nimport random\nfrom random import randrange\n\nimport os\nimport sys\nimport logging\nimport pickle\nimport json","metadata":{"execution":{"iopub.status.busy":"2024-10-13T21:24:58.852217Z","iopub.execute_input":"2024-10-13T21:24:58.852466Z","iopub.status.idle":"2024-10-13T21:24:58.860877Z","shell.execute_reply.started":"2024-10-13T21:24:58.852440Z","shell.execute_reply":"2024-10-13T21:24:58.860290Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"np.set_printoptions(precision=4)\n\n# Set the multiprocessing start method to 'spawn' to avoid issues with forking and GPU/TPU.\n# mp.set_start_method('spawn', force=True)\n\n# Set this to True if you want to use hardware acceleration (GPU/TPU)\naccelerate = True\n\n# sys.path.insert(1, '/kaggle/input/checkpoint-2-5-files')","metadata":{"execution":{"iopub.status.busy":"2024-10-13T21:24:58.862399Z","iopub.execute_input":"2024-10-13T21:24:58.862654Z","iopub.status.idle":"2024-10-13T21:24:58.869553Z","shell.execute_reply.started":"2024-10-13T21:24:58.862629Z","shell.execute_reply":"2024-10-13T21:24:58.868973Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"%run /kaggle/input/checkpoint-3-5/routine_error_correction.ipynb\n%run /kaggle/input/checkpoint-3-5/routine_helper1.ipynb\n%run /kaggle/input/checkpoint-3-5/routine_key.ipynb\n%run /kaggle/input/checkpoint-3-5/routine_plot_cascade1.ipynb\n# \n# %run /kaggle/input/checkpoint-3-5/routine_error_correction.ipynb","metadata":{"execution":{"iopub.status.busy":"2024-10-13T21:24:58.870314Z","iopub.execute_input":"2024-10-13T21:24:58.870551Z","iopub.status.idle":"2024-10-13T21:24:59.003961Z","shell.execute_reply.started":"2024-10-13T21:24:58.870527Z","shell.execute_reply":"2024-10-13T21:24:59.003318Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Function to select the appropriate hardware accelerator (GPU, TPU, or CPU)\ndef select_device():\n    if accelerate:\n        try:\n            # Check for TPU availability\n            tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n            print('Running on TPU:', tpu.cluster_spec().as_dict())\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.TPUStrategy(tpu)\n            return strategy\n        except ValueError:\n            # If TPU is not available, check for GPU\n            gpus = tf.config.list_physical_devices('GPU')\n            if gpus:\n                print(\"Running on GPU\")\n                return None  # TensorFlow will automatically use available GPU\n            else:\n                print(\"Running on CPU (NumPy)\")\n                return None\n    else:\n        print(\"Accelerate is False, running on CPU (NumPy).\")\n        return None\n\n# Select device (GPU/TPU/CPU)\nstrategy = select_device()","metadata":{"execution":{"iopub.status.busy":"2024-10-13T21:24:59.004835Z","iopub.execute_input":"2024-10-13T21:24:59.005071Z","iopub.status.idle":"2024-10-13T21:25:07.693533Z","shell.execute_reply.started":"2024-10-13T21:24:59.005047Z","shell.execute_reply":"2024-10-13T21:25:07.692692Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Running on TPU: {}\nINFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1728854703.398697      13 service.cc:145] XLA service 0x570ea366e060 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1728854703.398750      13 service.cc:153]   StreamExecutor device (0): TPU, 2a886c8\nI0000 00:00:1728854703.398755      13 service.cc:153]   StreamExecutor device (1): TPU, 2a886c8\nI0000 00:00:1728854703.398758      13 service.cc:153]   StreamExecutor device (2): TPU, 2a886c8\nI0000 00:00:1728854703.398760      13 service.cc:153]   StreamExecutor device (3): TPU, 2a886c8\nI0000 00:00:1728854703.398763      13 service.cc:153]   StreamExecutor device (4): TPU, 2a886c8\nI0000 00:00:1728854703.398765      13 service.cc:153]   StreamExecutor device (5): TPU, 2a886c8\nI0000 00:00:1728854703.398768      13 service.cc:153]   StreamExecutor device (6): TPU, 2a886c8\nI0000 00:00:1728854703.398771      13 service.cc:153]   StreamExecutor device (7): TPU, 2a886c8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"}]},{"cell_type":"code","source":"help(Key)","metadata":{"execution":{"iopub.status.busy":"2024-10-13T21:25:07.694503Z","iopub.execute_input":"2024-10-13T21:25:07.694756Z","iopub.status.idle":"2024-10-13T21:25:07.700943Z","shell.execute_reply.started":"2024-10-13T21:25:07.694728Z","shell.execute_reply":"2024-10-13T21:25:07.700265Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Help on class Key in module __main__:\n\nclass Key(AliceBob)\n |  Key(index, key_length=None, snr_db=None, *, Eve=None, signal_power=0.15, memory_efficient=True)\n |  \n |  Method resolution order:\n |      Key\n |      AliceBob\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  NoisyChannel(self)\n |      Simulates a noisy quantum channel where Pauli errors (X - bit flip; Z - phase flip)\n |      occur considering SNR.\n |      \n |      Parameters:\n |      - errors: A list to keep track of the number of bit-flip (X) and phase-flip (Z) errors.\n |      - snr_db: Signal-to-Noise Ratio in dB. This affects the probability of errors.\n |      \n |      Returns:\n |      - errors: Updated list with the number of X and Z errors introduced.\n |  \n |  __init__(self, index, key_length=None, snr_db=None, *, Eve=None, signal_power=0.15, memory_efficient=True)\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  amplify_privacy(self)\n |  \n |  append_reserves(self, reserve_i)\n |  \n |  calculate_meta_qber(self)\n |      This function calculates the QBER before applying channel encoding. Can not be used in actual implementation. Only for simulations\n |  \n |  correct(self, ECC='hamming')\n |  \n |  correct_cascade(self)\n |  \n |  correct_hamming(self)\n |  \n |  describe(self)\n |  \n |  encode_states(self, name)\n |      This function encodes each bit into the given basis.\n |  \n |  fill_block(self, order)\n |  \n |  generate_random_bases(self, name)\n |      This function selects a random basis for each bit\n |  \n |  generate_random_bits(self, name)\n |      This function generates a random array of bits(0/1) of size = key length\n |  \n |  measure(self, name)\n |      This function measures each qubit in the corresponding basis chosen for it.\n |  \n |  sift(self)\n |      This function sifts through the bases of both Alice and Bob and checks for the ones that match\n |  \n |  spot(self)\n |  \n |  ----------------------------------------------------------------------\n |  Class methods defined here:\n |  \n |  distribute(Keys, num=None, size=None) from builtins.type\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  error_prob = 0\n |  \n |  log = ' Class created'\n |  \n |  memory_efficient = 1\n |  \n |  num_keys = 0\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from AliceBob:\n |  \n |  current_length(self)\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from AliceBob:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Progress tracking (simple tracker)\ndef track(batch_idx, num_batches):\n    progress = (batch_idx + 1)/num_batches * 100\n    print(f\"\\rProgress: {progress:.2f}%\", end = '')","metadata":{"execution":{"iopub.status.busy":"2024-10-13T21:25:07.701893Z","iopub.execute_input":"2024-10-13T21:25:07.702148Z","iopub.status.idle":"2024-10-13T21:25:07.717741Z","shell.execute_reply.started":"2024-10-13T21:25:07.702122Z","shell.execute_reply":"2024-10-13T21:25:07.717028Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Generate, encode(in states), noise, measurement\nclass Key(AliceBob):\n        \n    log = ' Class created'\n    num_keys = 0\n    error_prob = 0    # Equivalent to BER\n\n    memory_efficient = 1\n    if not memory_efficient:\n        kept = np.array([], int)\n        discarded = np.array([], int)\n        BitsReservoir = [np.array([], dtype='<U11'), np.array([], dtype='<U11')]  # Use a sufficiently large dtype\n        BasesReservoir = np.array([], dtype='<U1')  # Assuming bases are single-character strings ('X', 'Z')\n        Reservoir = {}\n\n    \n    def __init__(self, index, key_length = None, snr_db = None, *, Eve = None, signal_power = 0.15, memory_efficient = True):\n        # self.original_key = np.random.randint(0, 2, key_length)  # Random key\n\n        if key_length is None: key_length = 1024\n        if snr_db is None: snr_db = 15\n        if memory_efficient is None: memory_efficient = False\n\n        Key.memory_efficient = memory_efficient\n\n        self.classical_ber = 0\n        self.meta_qber = 0\n        self.spot_qber = 0\n        self.corrected_qber = 0\n        \n        self.key_length = key_length    # Desired key length. NOT to be confused with the actual key length\n        self.snr_db = snr_db\n        self.signal_power = signal_power\n        self.qber = 0.    # Before CE. All the errors are due to quantum disturbances\n        self.ber = 0.\n        self.meta_qber = 0. \n        self.index = index\n        \n        self.sift_indices = None\n        self.final_key = np.array([], dtype='<U11')   # The key object itself can serve as a final key\n        self.qc = [QuantumCircuit(1, 1) for _ in range(self.key_length)]    # Initializing the circuit\n        self.remarks = 'Initialized'\n        self.errors_induced = np.array([0, 0])    # [bit-flip, phase-flip]\n        self.status = ''\n        \n        self.Alice = AliceBob(\"Alice\")\n        self.Bob = AliceBob(\"Bob\")\n        if Eve is not None: self.Eve = AliceBob(\"Eve\")\n\n        # The length that's needed to create a key of length key_length\n        self.redundant_len = int(self.key_length + np.ceil(np.log2(self.key_length)) + 1)\n### bits, bases = str, str\n\n    def describe(self):\n        # print(f' {self.original_key = }, type: {type(self.original_key)}, {len(self.original_key) = }')\n        print(f' {self.qber = },\\t type: {type(self.qber)}')\n        print(f' {self.ber = },\\t type: {type(self.ber)}')\n    \n        print(f' Desired Key Length: {self.key_length},\\t type: {type(self.key_length)}')\n        print(f' {self.snr_db = },\\t type: {type(self.snr_db)}')\n        print(f' {self.signal_power = },\\t type: {type(self.signal_power)}')\n        print(f' {self.index = },\\t type: {type(self.index)}')\n        \n        print(f' {self.sift_indices = },\\t type: {type(self.sift_indices)},\\t {sum(self.sift_indices) = }')\n        print(f' {self.final_key = },\\t type: {type(self.final_key)},\\t {len(self.final_key) = }')\n        print(f' self.qc : \\t type of elements: {type(self.qc[0])},\\t {len(self.qc) = }')\n        print(f' {self.remarks = },\\t type: {type(self.remarks)},\\t {len(self.remarks) = }')\n        print(f' {self.status = },\\t type: {type(self.status)},\\t {len(self.status) = }')\n        \n        print(f' {self.errors_induced = },\\t type: {type(self.errors_induced)},\\t {len(self.errors_induced) = }')\n\n        print(f' {self.Alice = },\\t type: {type(self.Alice)}')\n        print(f' {self.Bob = },\\t type: {type(self.Bob)}')\n        print(f' {self.Eve = },\\t type: {type(self.Eve)}')\n\n        print(f' {self.redundant_len = },\\t type: {type(self.redundant_len)}')\n\n    \n    def generate_random_bits(self, name):\n        \"\"\"This function generates a random array of bits(0/1) of size = key length\"\"\"\n        obj = self.Alice if name == \"Alice\" else self.Eve if name == \"Eve\" else ''\n        # for _ in range(self.key_length):\n            # rand_bit = random.randint(0, 1)     # = np.random.randint(0, 2)Flip Coin\n            # obj.bit_string = np.concatenate((obj.bit_string, [rand_bit]))\n        bit_string = np.random.randint(0, 2, self.key_length)\n        obj.bit_string = np.array(bit_string).astype(str)\n        self.remarks += f'\\n {name}: Random Bits generated'\n### bits, bases = str, str\n    \n    def generate_random_bases(self, name):\n        \"\"\"This function selects a random basis for each bit\"\"\"\n        obj = self.Alice if name == \"Alice\" else self.Bob if name == \"Bob\" else self.Eve if name == \"Eve\" else ''\n        # for _ in range(self.key_length):\n        #     randBasis = random.randint(0, 1)     # Flip Coin\n        #     obj.bases = np.concatenate((obj.bases, [\"X\"] if randBasis else [\"Z\"]))\n        obj.bases = np.random.choice(['X', 'Z'], self.key_length)\n        self.remarks += f'\\n {name}: Random Bases generated'\n### bits, bases = str, str\n        \n    def encode_states(self, name):\n        \"\"\"This function encodes each bit into the given basis.\"\"\"      \n        obj = self.Alice if name == \"Alice\" else self.Eve if name == \"Eve\" else ''\n        for i in range(self.key_length):\n            # Possible Cases\n            if obj.bit_string[i] == \"1\": self.qc[i].x(0)\n            if obj.bases[i] == 'X': self.qc[i].h(0)\n        \n        self.remarks += f'\\n {name}: States Encoded'\n\n        \n    def NoisyChannel(self):\n        ''' \n        Simulates a noisy quantum channel where Pauli errors (X - bit flip; Z - phase flip)\n        occur considering SNR.\n        \n        Parameters:\n        - errors: A list to keep track of the number of bit-flip (X) and phase-flip (Z) errors.\n        - snr_db: Signal-to-Noise Ratio in dB. This affects the probability of errors.\n        \n        Returns:\n        - errors: Updated list with the number of X and Z errors introduced.\n        '''\n        # Calculate BER\n        # Key.error_prob = snr2ber(self.snr_db)\n        # print(f'BER = {Key.error_prob}')\n        self.errors_induced[0] = 0\n        self.errors_induced[1] = 0\n               \n        # Simulate AWGN effect by modifying measurement outcomes based on noise\n        for i in range(self.key_length):\n            if random.random() < Key.error_prob:\n                self.qc[i].x(0)  # Simulate a bit-flip error due to noise\n                self.errors_induced[0] += 1\n                \n            if random.random() < Key.error_prob:\n                self.qc[i].z(0)  # Simulate a phase-flip error due to noise\n                self.errors_induced[1] += 1\n\n        self.remarks += '\\n Key Transmitted'    # \\n \"bases\" AND \"bit_string\" RESETTED'\n\n\n    def measure(self, name):\n        \"\"\"This function measures each qubit in the corresponding basis chosen for it.\"\"\"\n        obj = self.Bob if name == \"Bob\" else self.Eve if name == \"Eve\" else ''\n\n        for i in range(self.key_length):\n            if obj.bases[i] == \"X\": \n                self.qc[i].h(0)\n\n            self.qc[i].measure(0, 0)\n\n            # Execute on Simulator\n            simulator = Aer.get_backend('qasm_simulator')\n            transpiled_circuit = transpile(self.qc[i], simulator)\n            result = simulator.run(transpiled_circuit, shots = 1).result()\n            counts = result.get_counts()\n            measured_bit = max(counts, key = counts.get)     # Max doesn't matter for simulator since there is only one shot.\n    \n            obj.bit_string = np.concatenate((obj.bit_string, [measured_bit]))\n        \n        self.remarks += f'\\n {name}: States Measured'\n### bits, bases = str, str\n    \n    def sift(self):\n        \"\"\"This function sifts through the bases of both Alice and Bob and checks for the ones that match\"\"\"\n        self.sift_indices = (self.Bob.bases == self.Alice.bases)    # BROADCAST = self.Alice.bases\n        \n        self.Bob.bases = self.Bob.bases[self.sift_indices]\n        self.Alice.bases = self.Alice.bases[self.sift_indices]\n\n        self.Bob.bit_string = np.array(self.Bob.bit_string)[self.sift_indices]\n        self.Alice.bit_string = np.array(self.Alice.bit_string)[self.sift_indices]\n    \n        # self.Bob.bit_string = ''.join(self.Bob.bit_string)\n        self.remarks += f'\\n Key Sifted. Sift length = {sum(self.sift_indices)}'\n### bits, bases = Array, str\n\n    def spot(self):\n        sample = len(self.Alice.bit_string)//3    # len(self.Alice.bit_string) >= 3\n        errors_detected = 0\n        print('\\n Spotting(index, (alice, bob)): ', end = '  ')\n        for _ in range(sample):\n            bit_index = random.randrange(len(self.Alice.bit_string))\n            # print(self.Alice.bit_string[bit_index], self.Bob.bit_string[bit_index], end = '   ')\n            \n            self.Alice.bit_string = list(self.Alice.bit_string)  # Convert to a list if it's a numpy array\n            self.Bob.bit_string = list(self.Bob.bit_string)\n\n            print(f\"{bit_index}, ({self.Alice.bit_string[bit_index]}, {self.Bob.bit_string[bit_index]})\", end = '   ')\n            if self.Alice.bit_string[bit_index] != self.Bob.bit_string[bit_index]:  errors_detected += 1    # calculating errors\n            # Remove the bit at `bit_index`\n            self.Alice.bit_string = self.Alice.bit_string[:bit_index] + self.Alice.bit_string[bit_index+1:]\n            self.Bob.bit_string = self.Bob.bit_string[:bit_index] + self.Bob.bit_string[bit_index+1:]\n            \n            # Convert back to the numpy array (if needed) after manipulation\n            self.Alice.bit_string = np.array(self.Alice.bit_string)\n            self.Bob.bit_string = np.array(self.Bob.bit_string)\n            \n        \n        # order = np.ceil(np.log2(len(self.Alice.bit_string))).astype(int)\n        order = Order(self.Alice.bit_string)\n        \n        self.qber = errors_detected/sample    # calculating QBER\n        self.qber = round(self.qber, 2)    # saving the answer to two decimal places\n        \n        print(\"\\nQBER value = \", self.qber)\n        # print(\"alices secret key =\", self.Alice.bit_string)\n        # print(\"Bob secret key  =  \", self.Bob.bit_string)\n\n        return errors_detected\n\n\n    def calculate_meta_qber(self):    # Observer: This data is available only because we are observing from top. Won't be available to users.\n        \"\"\"This function calculates the QBER before applying channel encoding. Can not be used in actual implementation. Only for simulations\"\"\"\n        meta_qber = np.sum(self.Alice.bit_string != self.Bob.bit_string)/self.Bob.current_length()\n        self.meta_qber = meta_qber\n        return meta_qber\n\n\n    def append_reserves(self, reserve_i):\n\n        alice_bit_string = np.array(self.Alice.bit_string[reserve_i:], dtype='<U11')  # Adjust dtype to match\t\t\n        bob_bit_string = np.array(self.Bob.bit_string[reserve_i:], dtype='<U11')  # Adjust dtype to match\n\n        if not Key.memory_efficient:\n            Key.Reservoir.update({self.index: (self.Bob.bases, self.Bob.bit_string, self.Alice.bit_string)})\n            Key.BitsReservoir[0] = np.concatenate((Key.BitsReservoir[0], alice_bit_string))\n            Key.BitsReservoir[1] = np.concatenate((Key.BitsReservoir[1], bob_bit_string))\n            Key.BasesReservoir = np.concatenate((Key.BasesReservoir, self.Bob.bases[reserve_i:]))\n\n        self.Alice.bit_string = self.Alice.bit_string[:reserve_i]\n        self.Bob.bit_string = self.Bob.bit_string[:reserve_i]\n        self.Alice.bases = self.Alice.bases[:reserve_i]\n        self.Bob.bases = self.Bob.bases[:reserve_i]\n# Bits/Bases trimmed\n\n    def fill_block(self, order):\n        fill_length = int(2**order - order - 1) - sum(self.sift_indices)\n        filler = np.zeros(fill_length)\n        return filler\n        \n\n    def correct(self, ECC = 'hamming'):\n        if ECC == 'hamming': self.correct_hamming()\n        elif ECC == 'cascade': self.correct_cascade()\n\n\n    def correct_cascade(self):\n        error, (kcorrA, kcorrB) = biconf(self.qber, self.Alice.bit_string, self.Bob.bit_string)\n        self.Alice.bit_string, self.Bob.bit_string = kcorrA, kcorrB\n\n        \n    def correct_hamming(self):\n        channel_code = HammingCode()\n\n        self.Alice.bit_string[:] = np.array([int(bit) for bit in self.Alice.bit_string])\n        self.Bob.bit_string[:] = np.array([int(bit) for bit in self.Bob.bit_string])\n        block_order = channel_code.calculate_order(sum(self.sift_indices))\n\n        # Creating the PARITY dictionary to be sent on a classical channel\n        PARITY_DICT = channel_code.init_parity_dict(block_order)\n        # Embedding the PARITY bits in alice's bit strings to form a block\n        Alice_key_block, PARITY_DICT, num_fillers = channel_code.create_block_w_parity(self.Alice.bit_string, PARITY_DICT, encode = True)\n\n        # Broadcasting on a classical channel\n        BROADCAST = PARITY_DICT\n\n        # Embedding the PARITY bits(received on the classical channel from alice) in bob's bit strings to form a block\n        Bob_key_block, _, _ = channel_code.create_block_w_parity(self.Bob.bit_string, BROADCAST, encode = False)\n\n        # reserve_i = int(self.Alice.current_length() - num_extras)\n        # self.append_reserves(reserve_i)\n\n        print(f'\\t# {PARITY_DICT = }')\n        print_info([Alice_key_block, Bob_key_block], '[Extended] Key BLOCKS(Alice-Bob Parity Encoded): ', True)\n        print_info([self.Alice.bit_string, self.Bob.bit_string, self.Alice.bases, self.Bob.bases], 'Key strings(During Correction -- Not corrected): ', True)\n        \n        # Applying the hamming algorithm to: detect upto 2 bit errors and correct a single-bit error. \n        err_count, loc = channel_code.Apply_on(Bob_key_block, self.index)\n        print(f\" \\t # {err_count = }, {loc = }, binary_rep = {bin(loc)[2:].zfill(block_order)}\")\n        \n        if err_count != 0:\n            try: \n                if err_count == 1: \n                    Bob_key_block[loc] = np.mod(Bob_key_block[loc] + 1, 2)\n                    print(\" \\t - ERROR CORRECTED! Keeping the Key!\")\n                    self.status = 'keep'\n    \n                    if not Key.memory_efficient:\n                        Key.kept = np.concatenate((Key.kept, [self.index]))\n\n                else:\n                    print(\" \\t - Discarding the Key!\")\n                    self.status = 'discard'\n\n                    if not Key.memory_efficient:\n                        Key.discarded = np.concatenate((Key.discarded, [self.index]))\n                    \n            except:\n                raise KeyError('Location Invalid')\n\n        for j, bit in enumerate(Bob_key_block):    # Or alice_bits, since both should be the same\n            if j not in PARITY_DICT:\n                self.Bob.key = np.concatenate((self.Bob.key, [bit]))\n\n        # print(f'\\t - Length of Sifted Key = {sum(self.sift_indices)}')\n        self.Bob.key = self.Bob.key[:sum(self.sift_indices)]\n        self.Bob.bit_string = self.Bob.key\n        \n        self.Alice.bit_string = np.array(self.Alice.bit_string, dtype='<U11')\n        # self.Alice.bit_string = np.concatenate((self.Alice.bit_string, np.zeros(num_fillers, dtype='<U11')))\n\n        self.remarks += f'\\n {err_count} error(s) corrected'\n### bits, bases = str, str\n\n    def amplify_privacy(self):\t\t\n        #Generating seed (salt)\n        seed = []\n        for i in self.Alice.bit_string:\n            a = randrange(2)\n            seed.append(a)\n        \n        #Adding seeds to the keys\n        self.Alice.bit_string = np.concatenate((self.Alice.bit_string, seed))\n        self.Bob.bit_string = np.concatenate((self.Bob.bit_string, seed))\n        \n        #Converting lists to strings\n        self.Alice.bit_string = ' '.join([str(elem) for elem in self.Alice.bit_string])\n        self.Bob.bit_string = ' '.join([str(elem) for elem in self.Bob.bit_string])\n        \n        #checking first bit to decide hash function to use\n        if self.Alice.bit_string[0] == 1:\n            resultA = hashlib.sha256(self.Alice.bit_string.encode())\n            self.Alice.amp_key = bin(int(resultA.hexdigest(), 16))[2:]\n        else:\n            resultA = hashlib.sha3_256(self.Alice.bit_string.encode())\n            self.Alice.amp_key = bin(int(resultA.hexdigest(), 16))[2:]\n        \n        print()\n        if self.Bob.bit_string[0] == 1:\n            resultB = hashlib.sha256(self.Bob.bit_string.encode())\n            self.Bob.amp_key = bin(int(resultB.hexdigest(), 16))[2:]\n        else:\n            resultB = hashlib.sha3_256(self.Bob.bit_string.encode())\n            self.Bob.amp_key = bin(int(resultB.hexdigest(), 16))[2:]\n            \n    \n    @classmethod\n    def distribute(cls, Keys, num = None, size = None):\n\n        if num == None: num = 16\n        if size == None: size = 64\n            \n        # Accumulating all the keys and bases in their respective reservoirs\n        for i in range(cls.num_keys):\n            # Convert Alice's bit strings to strings and concatenate\n            alice_bit_string = np.array(Keys[i].Alice.bit_string, dtype = '<U11')  # Adjust dtype to match\n            cls.BitsReservoir[0] = np.concatenate((cls.BitsReservoir[0], alice_bit_string))\n            \n            bob_bit_string = np.array(Keys[i].Bob.bit_string, dtype = '<U11')  # Adjust dtype to match\n            cls.BitsReservoir[1] = np.concatenate((cls.BitsReservoir[1], bob_bit_string))\n\n            cls.BasesReservoir = np.concatenate((cls.BasesReservoir, Keys[i].Bob.bases))\n            cls.Reservoir.update({i: (Keys[i].Bob.bases, Keys[i].Bob.bit_string, Keys[i].Alice.bit_string)})\n\n        # Distributing equal length keys to each key\n        cls.ReservoirLen = len(Key.BitsReservoir[0])\n        \n        key_len = int(size - np.log2(size) - 1)\n        j = 0\n        for i in range(0, num):\n            # Assign a portion of the BitsReservoir to Alice and Bob\n            Keys[i].Alice.bit_string = cls.BitsReservoir[0][j: j+key_len]\n            Keys[i].Alice.bases = cls.BasesReservoir[j: j+key_len]\n            Keys[i].Bob.bit_string = cls.BitsReservoir[1][j: j+key_len]\n            Keys[i].Bob.bases = cls.BasesReservoir[j: j+key_len]\n            j += key_len\n            \n        # Handling excess bits and bases\n        cls.excess_Alice = AliceBob(\"excess_Alice\")\n        cls.excess_Bob = AliceBob(\"excess_Bob\")\n        \n        cls.excess_Alice.bit_string = cls.BitsReservoir[0][j:]\n        cls.excess_Alice.bases = cls.BasesReservoir[j:]\n        cls.excess_Bob.bit_string = cls.BitsReservoir[1][j:]\n        cls.excess_Bob.bases = cls.BasesReservoir[j:]\n### bits, bases = str, str\n\n#############","metadata":{"execution":{"iopub.status.busy":"2024-10-13T21:25:07.719791Z","iopub.execute_input":"2024-10-13T21:25:07.720052Z","iopub.status.idle":"2024-10-13T21:25:07.770349Z","shell.execute_reply.started":"2024-10-13T21:25:07.720027Z","shell.execute_reply":"2024-10-13T21:25:07.769642Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"###############\ndef transfer_keys(snr_db, num_keys, key_length, signal_power, results, ECC='Cascade'):\n    \n    kept_i = np.zeros(num_keys, bool)\n    discarded_i = np.zeros(num_keys, bool)\n    Reservoir = {}\n    # meta_qber  = np.zeros(num_keys, float)\n    \n    num_err_before = np.zeros(num_keys, int)    # Equivalent to meta qber -- after sifting; before correction\n    num_err_after = np.zeros(num_keys, int)    # Equivalent to BER -- not accessible in realtime\n\n    Keys = np.zeros(num_keys, object)\n    for i in range(num_keys):\n\n        start_key = time.time()\n\n        Keys[i] = Key(i, key_length, snr_db)\n        key_i = Keys[i]\n\n        if i%10 == 0: \n            print(type(key_i))  # This should output <class 'Key'>\n            print(hasattr(key_i, 'calculate_meta_qber'))  # This should return True\n\n            key_i.generate_random_bits(\"Alice\")\n            key_i.generate_random_bases(\"Alice\")\n            print(key_i.Alice.bit_string)\n\n            key_i.encode_states(\"Alice\")\n            key_i.NoisyChannel()            \n            key_i.generate_random_bases(\"Bob\")\n            key_i.measure(\"Bob\")\n            key_i.sift()\n            print_info([key_i.Alice.bit_string, key_i.Bob.bit_string, key_i.Alice.bases, key_i.Bob.bases], string = 'After Sifting|Before spotting', info = True)\n            \n            num_err_before[i] = np.sum(key_i.Alice.bit_string != key_i.Bob.bit_string)\n            \n            key_i.spot()\n            print_info([key_i.Alice.bit_string, key_i.Bob.bit_string], string='After spotting | Before Cascade', info=True)\n            key_i.calculate_meta_qber()\n\n            ###########\n            qber = key_i.qber\n            alice_bits = key_i.Alice.bit_string\n            bob_bits = key_i.Bob.bit_string\n            print_info([alice_bits, bob_bits], string='Before Cascade(vars)', info = True)\n            \n            # Error correction based on QBER\n            if qber > 0.25: \n                print('\\n QBER > 0.25. Key Discarded')\n                key_i.status = 'discard'\n                discarded_i[i] = True\n                continue\n\n            bob_bits = cascade_biconf_error_correction(alice_bits, bob_bits, qber)\n            bob_bits = to_int_list(bob_bits)\n            key_i.status = 'keep'\n            kept_i[i] = True\n\n            num_err_after[i] = np.sum(key_i.Alice.bit_string != key_i.Bob.bit_string)\n            \n            try: print_info([alice_bits, bob_bits], string='After Cascade(vars)', info = True)\n            except: \n                ('WARNING! Alice Bits and Bob Bits have different dimensions.')\n                print(alice_bits, '\\n', bob_bits)\n                print(type(alice_bits), '\\n', type(bob_bits))\n\n            key_i.Alice.bit_string = alice_bits\n            key_i.Bob.bit_string = bob_bits\n            Reservoir.update({\n                key_i.index: (key_i.Bob.bases, key_i.Bob.bit_string, key_i.Alice.bit_string)\n            })\n\n            # Privacy Amplification\n            key_i.amplify_privacy()\n            print(key_i.Alice.amp_key, key_i.Bob.amp_key)\n\n\n        else: \n            key_i.generate_random_bits(\"Alice\")\n            key_i.generate_random_bases(\"Alice\")\n            key_i.encode_states(\"Alice\")\n            key_i.NoisyChannel()\n            key_i.generate_random_bases(\"Bob\")\n            key_i.measure(\"Bob\")\n            key_i.sift()\n\n            num_err_before[i] = np.sum(key_i.Alice.bit_string != key_i.Bob.bit_string)\n\n            key_i.spot()\n            key_i.calculate_meta_qber() # equivalent to num_err_before\n            \n            qber = key_i.qber\n            alice_bits = key_i.Alice.bit_string\n            bob_bits = key_i.Bob.bit_string\n            \n            print(f'{qber=}, {type(qber)=}')\n            print(f\"{results['avg_qber']=}, {type(results['avg_qber'])=}\")\n            # Error correction based on QBER\n            if qber > 0.25: \n                key_i.status = 'discard'\n                discarded_i[i] = True\n                continue\n                \n            bob_bits = cascade_biconf_error_correction(alice_bits, bob_bits, qber)\n\n            bob_bits = to_int_list(bob_bits)\n            key_i.status = 'keep'\n            kept_i[i] = True\n\n            num_err_after[i] = np.sum(key_i.Alice.bit_string != key_i.Bob.bit_string)\n\n            key_i.Alice.bit_string = alice_bits\n            key_i.Bob.bit_string = bob_bits\n            Reservoir.update({\n                key_i.index: (key_i.Bob.bases, key_i.Bob.bit_string, key_i.Alice.bit_string)\n            })\n\n            # Privacy Amplification\n            key_i.amplify_privacy()\n        ## END IF-ELSE\n\n        print(f'{qber=}, {type(qber)=}')\n        print(f\"{results['avg_qber']=}, {type(results['avg_qber'])=}\")\n\n        # Collecting data to average over number of keys; discarded key data won't be stored here\n        results['avg_qber'] += qber\n        results['avg_ber'] += key_i.ber\n        results['avg_meta_qber'] += key_i.meta_qber\n        results['avg_distilled_key_len'] += len(key_i.Bob.bit_string)\n        results['avg_total_time'] += time.time() - start_key\n               \n        results['avg_corrected_qber'] += sum(key_i.qber for i in kept_i)/sum(kept_i) if sum(kept_i) > 0 else 0\n        results['avg_corrected_ber'] += sum(key_i.ber for i in kept_i)/sum(kept_i) if sum(kept_i) > 0 else 0\n\n    #     # Save a checkpoint after each key\n    #     save_checkpoint({\n    #         'qber': key_i.qber,\n    #         'ber': key_i.ber,\n    #         'meta_qber': key_i.meta_qber,   # It is not capturing data of discarded keys; this part is skipped by \"continue\"\n    #         'corrected_qber': results['avg_corrected_qber'],\n    #         'corrected_ber': results['avg_corrected_ber'],\n    #         'distilled_key_len': len(key_i.Bob.bit_string)\n    #     }, checkpoint_file)\n    # ## END FOR\n\n    # Individual Key level - not averaged; plotted\n    # results['err_distribution_before'] = num_err_before     \n\n    ### End For\n    return Keys, kept_i, discarded_i, Reservoir","metadata":{"execution":{"iopub.status.busy":"2024-10-13T21:25:07.771286Z","iopub.execute_input":"2024-10-13T21:25:07.771550Z","iopub.status.idle":"2024-10-13T21:25:07.806904Z","shell.execute_reply.started":"2024-10-13T21:25:07.771523Z","shell.execute_reply":"2024-10-13T21:25:07.806166Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Assuming 'transfer_keys' is defined elsewhere and imported\n\ndef simulate_snr_range(SNR_RANGE, num_keys, key_length, signal_power):\n    # Initialize results for the entire SNR range\n    avg_results = {\n        'avg_qber': np.zeros(len(SNR_RANGE)),\n        'avg_ber': np.zeros(len(SNR_RANGE)),\n        'avg_corrected_qber': np.zeros(len(SNR_RANGE)),\n        'avg_corrected_ber': np.zeros(len(SNR_RANGE)),\n        'avg_meta_qber': np.zeros(len(SNR_RANGE)),\n        'avg_distilled_key_len': np.zeros(len(SNR_RANGE)),\n        'avg_total_time': np.zeros(len(SNR_RANGE)),\n        'avg_skr': np.zeros(len(SNR_RANGE)),\n        'avg_bps': np.zeros(len(SNR_RANGE)),\n        'keys_kept': np.zeros(len(SNR_RANGE)),\n        'keys_discarded': np.zeros(len(SNR_RANGE)),\n        'total_kept_bits': np.zeros(len(SNR_RANGE)),\n        # 'err_distribution_before': [None] * len(SNR_RANGE),  # For each SNR\n        # 'err_distribution_after': [None] * len(SNR_RANGE)\n    }\n\n    for snr_index, snr_db in enumerate(SNR_RANGE):\n        start_snr = time.time()\n#         print(f'Starting simulation for SNR = {snr_db}')\n        \n        Key.error_prob = snr2ber(snr_db)  # Compute error probability for the SNR\n\n        # Initialize storage for keys and errors for this SNR level\n        Key.errors_present = np.zeros(num_keys, int)\n        Key.errors_corrected = np.zeros(num_keys, int)\n        # Keys = np.zeros(num_keys, dtype='object')\n        \n        # Per-SNR-level results\n        results = {\n            'avg_qber': 0.0,\n            'avg_ber': 0.0,\n            'avg_meta_qber': 0.0,\n            'avg_corrected_qber': 0.0,\n            'avg_corrected_ber': 0.0,\n            'avg_distilled_key_len': 0.0,\n            'avg_total_time': 0.0,\n            # 'err_distribution_before': [],\n            # 'err_distribution_after': []\n        }\n\n        # Call the 'transfer_keys' function to simulate key exchange and error correction\n        Keys, kept_i, discarded_i, Reservoir = transfer_keys(snr_db, num_keys, key_length, signal_power, results)\n        \n        # Average over number of keys for this SNR\n        for dict_key in results.keys():\n            print(f\"{dict_key}: {results[dict_key]}, type={type(results[dict_key])}\")\n\n            if isinstance(results[dict_key], list):  # Append the error distributions\n                results[dict_key].append(results[dict_key])\n            else:\n                results[dict_key] = results[dict_key]/float(num_keys)  # Scalar values can be averaged\n\n        # Aggregate Results after error correction\n        total_kept_bits = np.sum([Keys[i].Bob.current_length() for i in range(num_keys) if kept_i[i]])\n        keys_kept = np.sum(kept_i)\n        time_taken = time.time() - start_snr\n        \n        avg_results['avg_skr'][snr_index] += keys_kept / time_taken if time_taken > 0 else 0\n        avg_results['avg_bps'][snr_index] += total_kept_bits / time_taken if time_taken > 0 else 0\n        avg_results['keys_discarded'][snr_index] += np.sum(discarded_i)\n        avg_results['keys_kept'][snr_index] += keys_kept\n        avg_results['total_kept_bits'][snr_index] += total_kept_bits\n\n        for dict_key in results.keys():\n            avg_results[dict_key][snr_index] += results[dict_key]  # Incrementally add results\n\n        # Clean up large variables to avoid memory buildup\n#         del Keys, results, Reservoir\n\n    # Return aggregated results for this batch\n    return avg_results","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-10-13T21:25:07.808018Z","iopub.execute_input":"2024-10-13T21:25:07.808284Z","iopub.status.idle":"2024-10-13T21:25:07.828392Z","shell.execute_reply.started":"2024-10-13T21:25:07.808257Z","shell.execute_reply":"2024-10-13T21:25:07.827689Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Monte Carlo Simulation incorporating the multiprocessing\ndef monte_carlo(num_keys, key_length, sample_size, SNR_RANGE, signal_power, batch_size=None):\n\n    start_time = time.time()\n\n    # Initialize the dictionary to store the running averages\n    avg_mcs_results = {\n        'avg_qber': np.zeros(len(SNR_RANGE)),\n        'avg_ber': np.zeros(len(SNR_RANGE)),\n        'avg_corrected_qber': np.zeros(len(SNR_RANGE)),\n        'avg_corrected_ber': np.zeros(len(SNR_RANGE)),\n        'avg_meta_qber': np.zeros(len(SNR_RANGE)),\n        'avg_distilled_key_len': np.zeros(len(SNR_RANGE)),\n        'avg_total_time': np.zeros(len(SNR_RANGE)),\n        \n        'avg_skr': np.zeros(len(SNR_RANGE)),\n        'avg_bps': np.zeros(len(SNR_RANGE)),\n        'keys_kept': np.zeros(len(SNR_RANGE)),\n        'keys_discarded': np.zeros(len(SNR_RANGE)),\n        'total_kept_bits': np.zeros(len(SNR_RANGE)),\n        \n        # 'err_distribution_before': [None] * len(SNR_RANGE),  \n        # 'err_distribution_after': [None] * len(SNR_RANGE)\n    }\n\n    # cores = cpu_count()  # Get the number of CPU cores\n    # if batch_size is None:\n    #     batch_size = cores\n\n    # total_samples = 0  # Keep track of total samples processed\n    # num_batches = int(np.ceil(sample_size / batch_size))\n#     # Multiprocessing Pool\n#     with mp.Pool(processes=cores) as pool:\n#         # Process each batch\n#         for batch_idx in range(num_batches):\n#             current_batch_size = min(batch_size, sample_size - total_samples)\n\n#             # Run simulations for the current batch in parallel using multiprocessing\n#             parallel_results = pool.starmap(simulate_snr_range, [(SNR_RANGE, num_keys, key_length, signal_power)\n#                                                                  for _ in range(current_batch_size)])\n\n#             # Update running averages after each batch\n#             for result in parallel_results:\n#                 for key in avg_mcs_results.keys():\n# #                     if isinstance(avg_mcs_results[key], list):\n# #                         # Handle lists (append results)\n# #                         for idx, values in enumerate(result[key]):\n# # #                             if avg_mcs_results[key][idx] is None:\n# # #                                 avg_mcs_results[key][idx] = values\n# # #                             else:\n# #                                  avg_mcs_results[key][idx] += values\n# #                     else:\n#                     avg_mcs_results[key] = (avg_mcs_results[key] * total_samples + result[key] * current_batch_size) / (total_samples + current_batch_size)\n\n#             total_samples += current_batch_size\n            \n#             track(batch_idx, num_batches)\n\n    for sample in range (sample_size):\n        results = simulate_snr_range(SNR_RANGE, num_keys, key_length, signal_power)\n        for key in avg_mcs_results.keys():\n            avg_mcs_results[key] += results[key]\n        track(sample, sample_size)\n    \n    for key in avg_mcs_results.keys():\n        avg_mcs_results[key] = avg_mcs_results[key]/sample_size\n\n    end_time = time.time()\n    print(f\"Monte Carlo simulation completed in {end_time - start_time:.2f} seconds.\")\n\n    return avg_mcs_results","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-10-13T21:25:07.829355Z","iopub.execute_input":"2024-10-13T21:25:07.829628Z","iopub.status.idle":"2024-10-13T21:25:07.858579Z","shell.execute_reply.started":"2024-10-13T21:25:07.829601Z","shell.execute_reply":"2024-10-13T21:25:07.857866Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"%%time\n# Example Simulation Parameters\nsample_size = int(1e2)  # 100,000 samples\ndesired_key_len = 32\nnum_keys = int(1e2)  # 1000 keys\nSNR_RANGE = np.arange(0, 12.5, 0.5)\nsignal_power = 0.15\n\nkey_length = 3*desired_key_len\nmemory_efficient = True\n\nKey.num_keys = num_keys\n# Run the Monte Carlo Simulation with multiprocessing and optional acceleration\nresults = monte_carlo(num_keys, key_length, sample_size, SNR_RANGE, signal_power)","metadata":{"execution":{"iopub.status.busy":"2024-10-13T21:25:07.859438Z","iopub.execute_input":"2024-10-13T21:25:07.859703Z","iopub.status.idle":"2024-10-13T21:25:25.099586Z","shell.execute_reply.started":"2024-10-13T21:25:07.859660Z","shell.execute_reply":"2024-10-13T21:25:25.098803Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"<class '__main__.Key'>\nTrue\n['0' '1' '1' '1' '0' '0' '1' '0' '1' '0' '1' '0' '0' '1' '1' '0' '0' '0'\n '1' '0' '0' '0' '1' '0' '0' '1' '0' '0' '0' '1' '0' '0' '1' '1' '1' '0'\n '0' '1' '1' '1' '1' '1' '0' '1' '0' '1' '1' '0' '0' '1' '0' '1' '0' '0'\n '1' '1' '0' '1' '1' '1' '0' '1' '1' '1' '1' '1' '0' '0' '0' '0' '0' '1'\n '0' '1' '1' '1' '1' '0' '0' '1' '1' '1' '1' '0' '1' '1' '1' '1' '1' '1'\n '0' '0' '0' '0' '1' '0']\n\n######## After Sifting|Before spotting\t\t\t ----- Number of Variables: 4, \t Number of Elements: 57\n-> Element Type: <class 'numpy.str_'>\n-> Variable Types: <class 'numpy.ndarray'>, <class 'numpy.ndarray'>, <class 'numpy.ndarray'>, <class 'numpy.ndarray'>\t ---> Variable Shapes: (57,), (57,), (57,), (57,)\n\n01ZZ <    11XX      00XX      10ZZ <    00ZZ      00ZZ      11ZZ      00ZZ      11XX      00XX      00ZZ      00XX      10ZZ <    01ZZ <    01ZZ <    10XX <    00XX      00ZZ      10ZZ <    00ZZ      00XX      11ZZ      01ZZ <    10XX <    00ZZ      01XX <    11XX      11XX      00XX      11ZZ      10XX <    10ZZ <    00XX      11XX      11XX      00ZZ      00XX      00ZZ      00XX      10ZZ <    11ZZ      11ZZ      10XX <    00ZZ      10XX <    11ZZ      11ZZ      11ZZ      11ZZ      11XX      10XX <    10ZZ <    01ZZ <    00ZZ      00XX      10ZZ <    00ZZ      \n\n Spotting(index, (alice, bob)):   31, (1, 0)   24, (0, 0)   21, (1, 1)   10, (0, 0)   43, (1, 1)   39, (0, 0)   0, (0, 1)   3, (0, 0)   28, (1, 1)   32, (1, 0)   1, (0, 0)   12, (0, 0)   4, (0, 0)   43, (0, 0)   14, (0, 0)   40, (0, 0)   36, (1, 0)   39, (1, 0)   36, (1, 0)   \nQBER value =  0.32\n\n######## After spotting | Before Cascade\t\t\t ----- Number of Variables: 2, \t Number of Elements: 38\n-> Element Type: <class 'numpy.str_'>\n-> Variable Types: <class 'numpy.ndarray'>, <class 'numpy.ndarray'>\t ---> Variable Shapes: (38,), (38,)\n\n11      10 <    00      11      11      00      00      10 <    01 <    01 <    10 <    00      10 <    00      01 <    10 <    01 <    11      11      00      11      10 <    00      11      00      00      00      00      11      11      10 <    10 <    11      11      11      11      01 <    00      \n\n######## Before Cascade(vars)\t\t\t ----- Number of Variables: 2, \t Number of Elements: 38\n-> Element Type: <class 'numpy.str_'>\n-> Variable Types: <class 'numpy.ndarray'>, <class 'numpy.ndarray'>\t ---> Variable Shapes: (38,), (38,)\n\n11      10 <    00      11      11      00      00      10 <    01 <    01 <    10 <    00      10 <    00      01 <    10 <    01 <    11      11      00      11      10 <    00      11      00      00      00      00      11      11      10 <    10 <    11      11      11      11      01 <    00      \n\n QBER > 0.25. Key Discarded\n\n Spotting(index, (alice, bob)):   1, (0, 1)   37, (1, 0)   33, (0, 0)   38, (0, 0)   31, (1, 1)   22, (0, 0)   32, (1, 0)   18, (1, 1)   7, (1, 1)   33, (1, 1)   4, (0, 1)   35, (0, 0)   9, (0, 0)   27, (1, 1)   32, (1, 1)   2, (0, 0)   23, (1, 1)   8, (1, 1)   \nQBER value =  0.22\nqber=0.22, type(qber)=<class 'float'>\nresults['avg_qber']=0.0, type(results['avg_qber'])=<class 'float'>\n\nqber=0.22, type(qber)=<class 'float'>\nresults['avg_qber']=0.0, type(results['avg_qber'])=<class 'float'>\n\n Spotting(index, (alice, bob)):   25, (0, 0)   25, (0, 0)   33, (1, 1)   33, (0, 0)   4, (0, 0)   0, (1, 1)   27, (0, 0)   30, (1, 1)   10, (0, 0)   26, (1, 1)   11, (0, 0)   22, (0, 0)   21, (1, 1)   \nQBER value =  0.0\nqber=0.0, type(qber)=<class 'float'>\nresults['avg_qber']=0.22, type(results['avg_qber'])=<class 'float'>\n\nqber=0.0, type(qber)=<class 'float'>\nresults['avg_qber']=0.22, type(results['avg_qber'])=<class 'float'>\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m<timed exec>:13\u001b[0m\n","Cell \u001b[0;32mIn[26], line 60\u001b[0m, in \u001b[0;36mmonte_carlo\u001b[0;34m(num_keys, key_length, sample_size, SNR_RANGE, signal_power, batch_size)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# cores = cpu_count()  # Get the number of CPU cores\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# if batch_size is None:\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m#     batch_size = cores\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m#             track(batch_idx, num_batches)\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (sample_size):\n\u001b[0;32m---> 60\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[43msimulate_snr_range\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSNR_RANGE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignal_power\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m avg_mcs_results\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     62\u001b[0m             avg_mcs_results[key] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m results[key]\n","Cell \u001b[0;32mIn[25], line 47\u001b[0m, in \u001b[0;36msimulate_snr_range\u001b[0;34m(SNR_RANGE, num_keys, key_length, signal_power)\u001b[0m\n\u001b[1;32m     34\u001b[0m results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_qber\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_ber\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# 'err_distribution_after': []\u001b[39;00m\n\u001b[1;32m     44\u001b[0m }\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Call the 'transfer_keys' function to simulate key exchange and error correction\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m Keys, kept_i, discarded_i, Reservoir \u001b[38;5;241m=\u001b[39m \u001b[43mtransfer_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43msnr_db\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignal_power\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Average over number of keys for this SNR\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dict_key \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mkeys():\n","Cell \u001b[0;32mIn[24], line 84\u001b[0m, in \u001b[0;36mtransfer_keys\u001b[0;34m(snr_db, num_keys, key_length, signal_power, results, ECC)\u001b[0m\n\u001b[1;32m     82\u001b[0m key_i\u001b[38;5;241m.\u001b[39mNoisyChannel()\n\u001b[1;32m     83\u001b[0m key_i\u001b[38;5;241m.\u001b[39mgenerate_random_bases(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBob\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 84\u001b[0m \u001b[43mkey_i\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBob\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m key_i\u001b[38;5;241m.\u001b[39msift()\n\u001b[1;32m     87\u001b[0m num_err_before[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(key_i\u001b[38;5;241m.\u001b[39mAlice\u001b[38;5;241m.\u001b[39mbit_string \u001b[38;5;241m!=\u001b[39m key_i\u001b[38;5;241m.\u001b[39mBob\u001b[38;5;241m.\u001b[39mbit_string)\n","Cell \u001b[0;32mIn[23], line 154\u001b[0m, in \u001b[0;36mKey.measure\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# Execute on Simulator\u001b[39;00m\n\u001b[1;32m    153\u001b[0m simulator \u001b[38;5;241m=\u001b[39m Aer\u001b[38;5;241m.\u001b[39mget_backend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqasm_simulator\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 154\u001b[0m transpiled_circuit \u001b[38;5;241m=\u001b[39m \u001b[43mtranspile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimulator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m result \u001b[38;5;241m=\u001b[39m simulator\u001b[38;5;241m.\u001b[39mrun(transpiled_circuit, shots \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    156\u001b[0m counts \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mget_counts()\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/qiskit/compiler/transpiler.py:366\u001b[0m, in \u001b[0;36mtranspile\u001b[0;34m(circuits, backend, basis_gates, inst_map, coupling_map, backend_properties, initial_layout, layout_method, routing_method, translation_method, scheduling_method, instruction_durations, dt, approximation_degree, timing_constraints, seed_transpiler, optimization_level, callback, output_name, unitary_synthesis_method, unitary_synthesis_plugin_config, target, hls_config, init_method, optimization_method, ignore_backend_supplied_default_methods, num_processes)\u001b[0m\n\u001b[1;32m    361\u001b[0m _check_circuits_coupling_map(circuits, coupling_map, backend)\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# Edge cases require using the old model (loose constraints) instead of building a target,\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# but we don't populate the passmanager config with loose constraints unless it's one of\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# the known edge cases to control the execution path.\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m pm \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_preset_pass_manager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimization_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbasis_gates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbasis_gates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoupling_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoupling_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstruction_durations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstruction_durations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend_properties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_properties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtiming_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtiming_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minst_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_layout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_layout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayout_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayout_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrouting_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouting_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtranslation_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranslation_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduling_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduling_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapproximation_degree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapproximation_degree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed_transpiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed_transpiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43munitary_synthesis_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munitary_synthesis_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43munitary_synthesis_plugin_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munitary_synthesis_plugin_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhls_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhls_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimization_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimization_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m out_circuits \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mrun(circuits, callback\u001b[38;5;241m=\u001b[39mcallback, num_processes\u001b[38;5;241m=\u001b[39mnum_processes)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, circ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(output_name, out_circuits):\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/qiskit/transpiler/preset_passmanagers/generate_preset_pass_manager.py:282\u001b[0m, in \u001b[0;36mgenerate_preset_pass_manager\u001b[0;34m(optimization_level, backend, target, basis_gates, inst_map, coupling_map, instruction_durations, backend_properties, timing_constraints, initial_layout, layout_method, routing_method, translation_method, scheduling_method, approximation_degree, seed_transpiler, unitary_synthesis_method, unitary_synthesis_plugin_config, hls_config, init_method, optimization_method, dt, _skip_target)\u001b[0m\n\u001b[1;32m    279\u001b[0m inst_map \u001b[38;5;241m=\u001b[39m _parse_inst_map(inst_map, backend)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# The basis gates parser will set _skip_target to True if a custom basis gate is found\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;66;03m# (known edge case).\u001b[39;00m\n\u001b[0;32m--> 282\u001b[0m basis_gates, name_mapping, _skip_target \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_basis_gates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbasis_gates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_skip_target\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m coupling_map \u001b[38;5;241m=\u001b[39m _parse_coupling_map(coupling_map, backend)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/qiskit/transpiler/preset_passmanagers/generate_preset_pass_manager.py:416\u001b[0m, in \u001b[0;36m_parse_basis_gates\u001b[0;34m(basis_gates, backend, inst_map, skip_target)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(instructions), name_mapping, skip_target\n\u001b[1;32m    414\u001b[0m instructions \u001b[38;5;241m=\u001b[39m instructions \u001b[38;5;129;01mor\u001b[39;00m backend\u001b[38;5;241m.\u001b[39moperation_names\n\u001b[1;32m    415\u001b[0m name_mapping\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 416\u001b[0m     {name: backend\u001b[38;5;241m.\u001b[39mtarget\u001b[38;5;241m.\u001b[39moperation_from_name(name) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m backend\u001b[38;5;241m.\u001b[39moperation_names}\n\u001b[1;32m    417\u001b[0m )\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# Check for custom instructions before removing calibrations\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inst \u001b[38;5;129;01min\u001b[39;00m instructions:\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/qiskit/transpiler/preset_passmanagers/generate_preset_pass_manager.py:416\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(instructions), name_mapping, skip_target\n\u001b[1;32m    414\u001b[0m instructions \u001b[38;5;241m=\u001b[39m instructions \u001b[38;5;129;01mor\u001b[39;00m backend\u001b[38;5;241m.\u001b[39moperation_names\n\u001b[1;32m    415\u001b[0m name_mapping\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 416\u001b[0m     {name: \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[38;5;241m.\u001b[39moperation_from_name(name) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m backend\u001b[38;5;241m.\u001b[39moperation_names}\n\u001b[1;32m    417\u001b[0m )\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# Check for custom instructions before removing calibrations\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inst \u001b[38;5;129;01min\u001b[39;00m instructions:\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/qiskit_aer/backends/aerbackend.py:423\u001b[0m, in \u001b[0;36mAerBackend.target\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    418\u001b[0m         target\u001b[38;5;241m.\u001b[39madd_instruction(\n\u001b[1;32m    419\u001b[0m             instruction\u001b[38;5;241m=\u001b[39mqiskit_control_flow_mapping[inst_name],\n\u001b[1;32m    420\u001b[0m             name\u001b[38;5;241m=\u001b[39minst_name,\n\u001b[1;32m    421\u001b[0m         )\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 423\u001b[0m         \u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_instruction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m            \u001b[49m\u001b[43minstruction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minst_name_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43minst_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproperties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprop_name_map\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minst_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coupling_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    430\u001b[0m     target\u001b[38;5;241m.\u001b[39m_coupling_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coupling_map\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mcopy()\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/qiskit/transpiler/target.py:432\u001b[0m, in \u001b[0;36mTarget.add_instruction\u001b[0;34m(self, instruction, properties, name)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TranspilerError(\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of qubits for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstruction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match the number \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof qubits in the properties dictionary: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqarg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m     )\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m qarg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_qubits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m--> 432\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_qubits \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_qubits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mqarg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    433\u001b[0m     )\n\u001b[1;32m    434\u001b[0m qargs_val[qarg] \u001b[38;5;241m=\u001b[39m properties[qarg]\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qarg_gate_map[qarg]\u001b[38;5;241m.\u001b[39madd(instruction_name)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"\nresults","metadata":{"execution":{"iopub.status.busy":"2024-10-13T21:25:25.100524Z","iopub.execute_input":"2024-10-13T21:25:25.100780Z","iopub.status.idle":"2024-10-13T21:25:25.126369Z","shell.execute_reply.started":"2024-10-13T21:25:25.100755Z","shell.execute_reply":"2024-10-13T21:25:25.125439Z"},"trusted":true},"execution_count":28,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\n","\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"],"ename":"NameError","evalue":"name 'results' is not defined","output_type":"error"}]}]}