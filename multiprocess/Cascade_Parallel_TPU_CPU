{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport time\nimport multiprocessing as mp\nimport tensorflow as tf\nfrom multiprocessing import cpu_count","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-09T06:19:04.704187Z","iopub.execute_input":"2024-10-09T06:19:04.704627Z","iopub.status.idle":"2024-10-09T06:19:21.354817Z","shell.execute_reply.started":"2024-10-09T06:19:04.704585Z","shell.execute_reply":"2024-10-09T06:19:21.353584Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Set the multiprocessing start method to 'spawn' to avoid issues with forking and GPU/TPU.\n# mp.set_start_method('spawn', force=True)\n\n# Set this to True if you want to use hardware acceleration (GPU/TPU)\naccelerate = True","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-09T06:19:21.357381Z","iopub.execute_input":"2024-10-09T06:19:21.358294Z","iopub.status.idle":"2024-10-09T06:19:21.367034Z","shell.execute_reply.started":"2024-10-09T06:19:21.358234Z","shell.execute_reply":"2024-10-09T06:19:21.364306Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"sys.path.insert(1, '/kaggle/input/dependencies-key')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to select the appropriate hardware accelerator (GPU, TPU, or CPU)\ndef select_device():\n    if accelerate:\n        try:\n            # Check for TPU availability\n            tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n            print('Running on TPU:', tpu.cluster_spec().as_dict())\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.TPUStrategy(tpu)\n            return strategy\n        except ValueError:\n            # If TPU is not available, check for GPU\n            gpus = tf.config.list_physical_devices('GPU')\n            if gpus:\n                print(\"Running on GPU\")\n                return None  # TensorFlow will automatically use available GPU\n            else:\n                print(\"Running on CPU (NumPy)\")\n                return None\n    else:\n        print(\"Accelerate is False, running on CPU (NumPy).\")\n        return None\n\n# Select device (GPU/TPU/CPU)\nstrategy = select_device()\n\n# Progress tracking (simple tracker)\ndef track(batch_idx, num_batches):\n    progress = (batch_idx + 1) / num_batches * 100\n    print(f\"\\rProgress: {progress:.2f}%\", end = '')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-09T06:19:21.369395Z","iopub.execute_input":"2024-10-09T06:19:21.371138Z","iopub.status.idle":"2024-10-09T06:19:21.425298Z","shell.execute_reply.started":"2024-10-09T06:19:21.371066Z","shell.execute_reply":"2024-10-09T06:19:21.423749Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Simulate SNR range (This function can be accelerated if 'accelerate' is True)\ndef simulate_snr_range(snr_range, num_keys, key_length, signal_power):\n    results = {\n        'avg_qber': np.zeros(len(snr_range)),\n        'avg_ber': np.zeros(len(snr_range)),\n        'avg_corrected_qber': np.zeros(len(snr_range)),\n        'avg_corrected_ber': np.zeros(len(snr_range)),\n        'keys_kept': np.zeros(len(snr_range)),\n        'keys_discarded': np.zeros(len(snr_range)),\n        'total_kept_bits': np.zeros(len(snr_range)),\n    }\n\n    if accelerate and strategy:  # Use TensorFlow for GPU/TPU\n        snr_tensor = tf.constant(snr_range, dtype=tf.float32)\n        for snr_idx, snr_db in enumerate(snr_range):\n            keys_kept = tf.reduce_sum(tf.random.uniform([num_keys], minval=0, maxval=2, dtype=tf.int32))\n            qber = tf.reduce_mean(tf.random.uniform([num_keys], minval=0.0, maxval=1.0, dtype=tf.float32))\n            results['avg_qber'][snr_idx] = qber.numpy()\n            results['keys_kept'][snr_idx] = keys_kept.numpy()\n    else:  # Use NumPy for CPU\n        for snr_idx, snr_db in enumerate(snr_range):\n            # Simulate the results for each SNR value using NumPy\n            results['avg_qber'][snr_idx] = np.mean(np.random.rand(num_keys))  # QBER simulation example\n            results['keys_kept'][snr_idx] = np.random.randint(0, num_keys)\n    \n    return results","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-09T06:19:21.369395Z","iopub.execute_input":"2024-10-09T06:19:21.371138Z","iopub.status.idle":"2024-10-09T06:19:21.425298Z","shell.execute_reply.started":"2024-10-09T06:19:21.371066Z","shell.execute_reply":"2024-10-09T06:19:21.423749Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Monte Carlo Simulation with multiprocessing and optional hardware acceleration\ndef monte_carlo(num_keys, key_length, sample_size, snr_range, signal_power, batch_size=None):\n    cores = cpu_count()  # Get the number of CPU cores\n    if batch_size is None:\n        batch_size = cores // 2  # Default to half the cores for batch size\n\n    start_time = time.time()\n\n    # Initialize the dictionary to store the running averages\n    avg_results = {\n        'avg_qber': np.zeros(len(snr_range)),\n        'avg_ber': np.zeros(len(snr_range)),\n        'avg_corrected_qber': np.zeros(len(snr_range)),\n        'avg_corrected_ber': np.zeros(len(snr_range)),\n        'keys_kept': np.zeros(len(snr_range)),\n        'keys_discarded': np.zeros(len(snr_range)),\n        'total_kept_bits': np.zeros(len(snr_range)),\n    }\n\n    # Total number of batches\n    num_batches = int(np.ceil(sample_size / batch_size))\n\n    # Counter to keep track of the total number of processed samples\n    total_samples = 0\n\n    # Multiprocessing Pool\n    with mp.Pool(processes=cores // 2) as pool:\n        # Process each batch\n        for batch_idx in range(num_batches):\n            # Determine the number of samples for this batch (handle last batch with fewer samples)\n            current_batch_size = min(batch_size, sample_size - total_samples)\n\n            # Run simulations for the current batch in parallel using multiprocessing\n            parallel_results = pool.starmap(simulate_snr_range, [(snr_range, num_keys, key_length, signal_power) for _ in range(current_batch_size)])\n\n            # Update running averages after each batch\n            for result in parallel_results:\n                for key in avg_results.keys():\n                    # Incrementally update running average\n                    avg_results[key] = (avg_results[key] * total_samples + np.array(result[key]) * current_batch_size) / (total_samples + current_batch_size)\n\n            # Update total number of samples processed so far\n            total_samples += current_batch_size\n\n            # Track progress\n            track(batch_idx, num_batches)\n\n    end_time = time.time()\n    print(f\"\\nMonte Carlo simulation completed in {end_time - start_time:.2f} seconds.\")\n\n    return avg_results","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-09T06:19:21.369395Z","iopub.execute_input":"2024-10-09T06:19:21.371138Z","iopub.status.idle":"2024-10-09T06:19:21.425298Z","shell.execute_reply.started":"2024-10-09T06:19:21.371066Z","shell.execute_reply":"2024-10-09T06:19:21.423749Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Running on CPU (NumPy)\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n# Example Simulation Parameters\nsample_size = int(1e5)  # 100,000 samples\nkey_length = 32\nnum_keys = int(1e3)  # 1000 keys\nSNR_RANGE = np.arange(0, 12.5, 0.5)\nsignal_power = 0.15\n\n# Run the Monte Carlo Simulation with multiprocessing and optional acceleration\nresults = monte_carlo(num_keys, key_length, sample_size, SNR_RANGE, signal_power)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-09T06:19:21.427070Z","iopub.execute_input":"2024-10-09T06:19:21.427486Z","iopub.status.idle":"2024-10-09T06:21:05.786332Z","shell.execute_reply.started":"2024-10-09T06:19:21.427444Z","shell.execute_reply":"2024-10-09T06:21:05.784956Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Progress: 100.00%Monte Carlo simulation completed in 104.34 seconds.\n","output_type":"stream"}]}]}